# 基于机器学习的文本分类实验报告

## 1. 任务背景与概述

本实验旨在实现基于logistic/softmax regression的文本分类，数据集为Rotten Tomatoes电影评论情感分析数据。根据电影评论的文本内容，预测其情感极性（分为0-4共5个类别，从最负面到最正面）。

实验要求使用NumPy实现各种机器学习算法，掌握文本特征表示方法（Bag-of-Words, N-gram）以及分类器（logistic/softmax regression）的原理和实现。同时，通过实验分析不同特征、损失函数、学习率等因素对分类性能的影响。

## 2. 数据集介绍

### 2.1 数据集来源与说明

本实验使用的是Rotten Tomatoes电影评论数据集，这是一个包含来自电影评论网站的文本内容及对应情感标签的数据集。数据集分为训练集和测试集两部分。

情感标签分为5个类别：
- 0: 极负面（Very Negative）
- 1: 负面（Negative）
- 2: 中性（Neutral）
- 3: 正面（Positive）
- 4: 极正面（Very Positive）

### 2.2 数据预处理

对原始数据进行了以下预处理步骤：
1. 文本清洗：将文本转为小写，去除标点符号和特殊字符，替换特殊标记（如-LRB-替换为左括号）
2. 分词：将文本分割为单词序列
3. 特征提取：将文本转换为数值特征向量，实现了Bag-of-Words、N-gram和TF-IDF三种特征表示方法
4. 数据集划分：将数据集划分为训练集、验证集和测试集

## 3. 模型与方法

### 3.1 文本特征表示

#### 3.1.1 Bag-of-Words (BOW)

Bag-of-Words是一种将文本表示为单词频率向量的方法。它首先构建词汇表，然后对于每个文档，统计词汇表中每个单词在文档中出现的次数，形成一个特征向量。

实现中，我们：
- 设置了最小词频阈值，过滤低频词
- 支持设置最大特征数量，只保留最高频的N个词
- 为每个文本构建词频向量

#### 3.1.2 N-gram

N-gram是考虑单词序列的特征表示方法，它将连续的N个单词视为一个特征。与BOW仅考虑单个词不同，N-gram能够捕捉词序关系。

实现中，我们：
- 支持自定义N的大小（默认为2，即bigram）
- 同样设置了最小频率阈值和最大特征数量限制
- 为每个文本统计N-gram的频率

#### 3.1.3 TF-IDF

TF-IDF（Term Frequency-Inverse Document Frequency）是对BOW的改进，它不仅考虑词频（TF），还引入了逆文档频率（IDF）来衡量词语的重要性。TF-IDF值高说明该词在当前文档中频繁出现但在其他文档中较少出现，具有较高的区分能力。

实现中，我们：
- 首先计算BOW特征
- 计算每个词的IDF值
- 将TF值乘以IDF值得到TF-IDF特征

### 3.2 分类模型

#### 3.2.1 Logistic回归（二分类）

Logistic回归是一种处理二分类问题的线性模型，它使用sigmoid函数将线性预测值映射到[0,1]区间作为概率输出。

实现中，我们：
- 使用二元交叉熵作为损失函数
- 添加L2正则化避免过拟合
- 使用小批量梯度下降进行优化
- 支持学习率、正则化系数等超参数调整

#### 3.2.2 Softmax回归（多分类）

Softmax回归是Logistic回归在多分类问题上的推广，它使用softmax函数将线性预测值转换为多个类别的概率分布。

实现中，我们：
- 使用交叉熵损失函数
- 添加L2正则化
- 使用小批量梯度下降
- 支持与Logistic回归相同的超参数调整

### 3.3 实验框架

我们构建了完整的实验框架，包括：
- 数据加载与预处理
- 特征提取
- 模型训练与评估
- 结果可视化
- 批量实验执行
- 结果分析与比较

## 4. 实验设计与分析

### 4.1 实验设计

为了全面评估不同特征和模型参数对分类性能的影响，我们设计了以下实验：

#### 实验1：不同特征类型比较
- 对比BOW、N-gram和TF-IDF三种特征表示方法在多分类Softmax回归模型上的性能表现

#### 实验2：不同特征类型在二分类问题上的比较
- 将多分类问题简化为二分类（正面vs负面），比较三种特征在Logistic回归上的性能

#### 实验3：学习率影响分析
- 使用BOW特征和Softmax回归，探究不同学习率（0.001, 0.005, 0.01, 0.05, 0.1）对模型性能的影响

#### 实验4：正则化系数影响分析
- 使用BOW特征和Softmax回归，探究不同正则化系数（0.0001, 0.001, 0.01, 0.1, 1.0）对模型性能的影响

#### 实验5：批量大小影响分析
- 使用BOW特征和Softmax回归，探究不同批量大小（8, 16, 32, 64, 128）对模型性能和训练效率的影响

### 4.2 评估指标

主要使用以下指标评估模型性能：
- 准确率（Accuracy）：正确预测的样本比例
- 学习曲线：训练过程中训练集和验证集损失的变化
- 混淆矩阵：各类别之间的预测关系
- 训练时间：模型训练所需时间

## 5. 实验结果与分析

### 5.1 不同特征类型的性能对比

（此处根据实验结果填写，包括各特征类型的准确率、训练时间等指标对比，并插入相关图表）

**分析：**
1. 特征表示方法对模型性能的影响
2. 各特征方法的优缺点分析
3. 特征维度与模型性能的关系

### 5.2 学习率对模型性能的影响

（此处根据实验结果填写，包括不同学习率下的模型表现对比，并插入相关图表）

**分析：**
1. 学习率过小/过大对收敛速度和最终性能的影响
2. 最佳学习率的选择依据
3. 学习率与其他因素的交互影响

### 5.3 正则化系数对模型性能的影响

（此处根据实验结果填写，包括不同正则化系数下的模型表现对比，并插入相关图表）

**分析：**
1. 正则化强度对过拟合/欠拟合的影响
2. 最佳正则化系数的选择依据
3. 正则化与特征类型的关系

### 5.4 批量大小对模型性能的影响

（此处根据实验结果填写，包括不同批量大小下的模型表现对比，并插入相关图表）

**分析：**
1. 批量大小对收敛速度和稳定性的影响
2. 批量大小与训练效率的关系
3. 最佳批量大小的选择依据

### 5.5 最佳模型性能总结

（此处根据所有实验中表现最佳的模型配置及其性能指标进行总结）

## 6. 总结与讨论

### 6.1 主要发现

总结实验中的关键发现：
1. 不同特征表示方法的性能差异和适用场景
2. 模型超参数对性能的影响规律
3. 针对此类文本分类问题的最佳实践建议

### 6.2 问题与挑战

在实验过程中遇到的主要问题与挑战：
1. 高维稀疏特征处理的挑战
2. 计算效率与内存消耗的平衡
3. 参数调优的复杂性

### 6.3 改进方向

可能的改进方向与未来工作：
1. 更先进的特征提取方法（如词嵌入）
2. 更复杂的模型结构（如神经网络）
3. 更高效的优化算法

## 7. 参考文献

1. Christopher M. Bishop. Pattern Recognition and Machine Learning. Springer, 2006.
2. Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep Learning. MIT Press, 2016.
3. 邱锡鹏. 神经网络与深度学习. 机械工业出版社, 2020.
4. [其他相关文献...]

## 附录

### A. 关键代码实现

（摘录实验中的关键代码段并进行解释）

### B. 实验详细结果

（提供完整的实验结果表格或其他补充材料）
